{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\19701\\Desktop\\MealMate\\env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\19701\\Desktop\\MealMate\\env\\lib\\site-packages\\huggingface_hub\\file_download.py:139: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\19701\\.cache\\huggingface\\hub\\datasets--Shengtao--recipe. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 32722/32722 [00:00<00:00, 34144.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"Shengtao/recipe\")\n",
    "\n",
    "print(len(ds['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai, os\n",
    "\n",
    "# api\n",
    "openai.api_key = \"\"\n",
    "\n",
    "def call_chatgpt_api(user_input, model=\"gpt-4o-mini\", system_message=\"You are a professional chef\"):\n",
    "    response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "        )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load BERT to calculate similarity score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:/Users/19701/AppData/Roaming/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt', download_dir='C:/Users/19701/AppData/Roaming/nltk_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "import torch\n",
    "from transformers import logging as transformers_logging\n",
    "\n",
    "# Suppress warnings from transformers\n",
    "transformers_logging.set_verbosity_error()\n",
    "\n",
    "# Load BERT model and tokenizer for cosine similarity and BERTScore\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Function to get BERT embeddings for cosine similarity\n",
    "def get_embedding(text):\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    return outputs.last_hidden_state.mean(dim=1).squeeze()\n",
    "\n",
    "# Cosine similarity score between two pieces of text\n",
    "def cosine_similarity_score(text1, text2):\n",
    "    emb1 = get_embedding(text1).numpy().reshape(1, -1)\n",
    "    emb2 = get_embedding(text2).numpy().reshape(1, -1)\n",
    "    return cosine_similarity(emb1, emb2)[0][0]\n",
    "\n",
    "# ROUGE scorer setup\n",
    "scorer = rouge_scorer.RougeScorer(['rouge1', 'rouge2', 'rougeL'], use_stemmer=True)\n",
    "\n",
    "# Function to calculate ROUGE-L score\n",
    "def rouge_l_score(expected, generated):\n",
    "    scores = scorer.score(expected, generated)\n",
    "    return scores['rougeL'].fmeasure\n",
    "\n",
    "# Function to calculate BERTScore\n",
    "def bert_score(expected_answers, generated_answers):\n",
    "    P, R, F1 = score(generated_answers, expected_answers, lang=\"en\", verbose=False)  # Disable verbose logging\n",
    "    return F1.mean().item()\n",
    "\n",
    "# Perform benchmarking\n",
    "def evaluate_benchmark(expected_answers, generated_answers):\n",
    "\n",
    "    expected = expected_answers\n",
    "    generated = generated_answers\n",
    "    print(f\"Standard ingredients: {expected}\")\n",
    "    print(f\"Generated ingredients: {generated}\")\n",
    "\n",
    "    \n",
    "    # Cosine Similarity\n",
    "    cosine_sim = cosine_similarity_score(expected, generated)\n",
    "    print(f\"Cosine Similarity: {cosine_sim:.4f}\")\n",
    "    \n",
    "    # ROUGE-L\n",
    "    rouge_l = rouge_l_score(expected, generated)\n",
    "    print(f\"ROUGE-L: {rouge_l:.4f}\")\n",
    "    \n",
    "    # BERTScore\n",
    "    bertscore_f1 = bert_score([expected], [generated])\n",
    "    print(f\"BERTScore F1: {bertscore_f1:.4f}\")\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "\n",
    "# Run the evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What's the ingredients of Simple Macaroni and Cheese? Please list the specific amount of each ingredient only, separate with semicolons.\n",
      "Standard ingredients: 1 (8 ounce) box elbow macaroni ; ¼ cup butter ; ¼ cup all-purpose flour ; ½ teaspoon salt ;   ground black pepper to taste ; 2 cups milk ; 2 cups shredded Cheddar cheese\n",
      "Generated ingredients: 8 ounces elbow macaroni; 2 tablespoons butter; 2 tablespoons all-purpose flour; 2 cups milk; 2 cups shredded sharp cheddar cheese; 1/2 teaspoon salt; 1/4 teaspoon black pepper; 1/4 teaspoon paprika (optional).\n",
      "Cosine Similarity: 0.9480\n",
      "ROUGE-L: 0.5161\n",
      "BERTScore F1: 0.9071\n",
      "\n",
      "\n",
      "Query: What's the ingredients of Gourmet Mushroom Risotto? Please list the specific amount of each ingredient only, separate with semicolons.\n",
      "Standard ingredients: 6 cups chicken broth, divided ; 3 tablespoons olive oil, divided ; 1 pound portobello mushrooms, thinly sliced ; 1 pound white mushrooms, thinly sliced ; 2  shallots, diced ; 1 ½ cups Arborio rice ; ½ cup dry white wine ;   sea salt to taste ;   freshly ground black pepper to taste ; 3 tablespoons finely chopped chives ; 4 tablespoons butter ; ⅓ cup freshly grated Parmesan cheese\n",
      "Generated ingredients: 1 cup Arborio rice; 4 cups vegetable or chicken broth; 1 cup dry white wine; 1 medium onion, finely chopped; 2 cloves garlic, minced; 8 oz mixed gourmet mushrooms (such as shiitake, cremini, and oyster), sliced; 2 tablespoons olive oil; 2 tablespoons unsalted butter; 1/2 cup grated Parmesan cheese; 1/4 cup fresh parsley, chopped; Salt and pepper to taste; Truffle oil (optional, for drizzling)\n",
      "Cosine Similarity: 0.9523\n",
      "ROUGE-L: 0.2623\n",
      "BERTScore F1: 0.8715\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "titles = ds['train']['title']\n",
    "ingredients = ds['train']['ingredients']\n",
    "\n",
    "for i in range(2):\n",
    "    title = titles[i]\n",
    "    query = f\"What's the ingredients of {title}? Please list the specific amount of each ingredient only, separate with semicolons.\"\n",
    "    print(f\"Query: {query}\")\n",
    "    \n",
    "    ## TODO: link to the chef de cuisine\n",
    "    response = call_chatgpt_api(query)\n",
    "    ingredient = ingredients[i]\n",
    "\n",
    "    \n",
    "    \n",
    "    evaluate_benchmark(ingredient, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C:\\\\Users\\\\19701/nltk_data', 'c:\\\\Users\\\\19701\\\\Desktop\\\\MealMate\\\\env\\\\nltk_data', 'c:\\\\Users\\\\19701\\\\Desktop\\\\MealMate\\\\env\\\\share\\\\nltk_data', 'c:\\\\Users\\\\19701\\\\Desktop\\\\MealMate\\\\env\\\\lib\\\\nltk_data', 'C:\\\\Users\\\\19701\\\\AppData\\\\Roaming\\\\nltk_data', 'C:\\\\nltk_data', 'D:\\\\nltk_data', 'E:\\\\nltk_data']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "print(nltk.data.path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
